{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLSF - Learning Label Specific Features for Multi-Label Classifcation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from numpy.linalg import inv\n",
    "from numpy import linalg as LA\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cossim\n",
    "from numpy import count_nonzero\n",
    "from sklearn.metrics import f1_score,hamming_loss,label_ranking_average_precision_score,zero_one_loss,auc,coverage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading already pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Wed May 04 19:29:54 2016',\n",
       " '__version__': '1.0',\n",
       " '__globals__': [],\n",
       " 'X': <391x72 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 27995 stored elements in Compressed Sparse Column format>,\n",
       " 'Y': <391x6 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 709 stored elements in Compressed Sparse Column format>,\n",
       " 'Xt': <202x72 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 14487 stored elements in Compressed Sparse Column format>,\n",
       " 'Yt': <202x6 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 399 stored elements in Compressed Sparse Column format>}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sio.loadmat('datasets/emotions.mat')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data['X'].toarray()\n",
    "Y=data['Y'].toarray()\n",
    "Xt=data['Xt'].toarray()\n",
    "Yt=data['Yt'].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setting Optimal parameters for LLSF (as suggested by authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optmParameter={}\n",
    "optmParameter['alpha']             = 2**(-5)       #label correlation\n",
    "optmParameter['beta']              = 2**(-3)       #sparsity\n",
    "optmParameter['gamma']             = 0.1           #initialization for W\n",
    "optmParameter['maxIter']           = 100           #Maximum iteration\n",
    "optmParameter['minimumLossMargin'] = 0.0001        #Setting condition for convergence\n",
    "optmParameter['Threshold']         = 0.5           #The threshold for classifying 0 or 1 for labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LLSF Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LLSF(X,Y,Xt,optmParameter):\n",
    "    \n",
    "    #This function outouts the weight matrix for features\n",
    "    def LLSF_weight_mat(X,Y,optmParameter):\n",
    "    \n",
    "    #Optimal Parameters\n",
    "    \n",
    "        alpha            = optmParameter['alpha']\n",
    "        beta             = optmParameter['beta']\n",
    "        gamma            = optmParameter['gamma']\n",
    "        maxIter          = optmParameter['maxIter']\n",
    "        miniLossMargin   = optmParameter['minimumLossMargin']\n",
    "    \n",
    "    #Initialisation\n",
    "    \n",
    "        num_dim          = X.shape[1]\n",
    "        XTX              = np.matmul(X.T,X)\n",
    "        XTY              = np.matmul(X.T,Y)\n",
    "        W_s              = np.matmul(inv(XTX + gamma * np.eye(num_dim)),XTY)\n",
    "        W_s_1            = W_s\n",
    "        eps              = 10**-8\n",
    "        R                = cossim(np.transpose(Y + eps),np.transpose(Y + eps))\n",
    "        Lip              = np.sqrt(2*np.power((LA.norm(XTX,'fro')),2) + np.power((LA.norm(alpha * R,'fro')),2))\n",
    "        bk               = 1\n",
    "        bk_1             = 1  \n",
    "    \n",
    "    #The Soft-thresholding function\n",
    "    \n",
    "        def softthres(W_t,lambd):\n",
    "            W = np.maximum((W_t-lambd),lambd) - np.maximum(-W_t-lambd,lambd)\n",
    "            return W\n",
    "        \n",
    "    #LLSF algorithm using Accelersted Proximal Gradient\n",
    "        oldloss             = 0\n",
    "        iteration           = 0\n",
    "        while iteration <= maxIter:\n",
    "            W_s_k           = W_s + ((bk_1 - 1)/bk) * (W_s - W_s_1)\n",
    "            Gw_s_k          = W_s_k - ((1/Lip) * ((np.matmul(XTX,W_s_k) - XTY + alpha * np.matmul(W_s_k,R))))\n",
    "            bk_1            = bk\n",
    "            bk              = (1 + np.sqrt(4*bk**2 + 1))/2\n",
    "            W_s_1           = W_s\n",
    "            W_s             = softthres(Gw_s_k,beta/Lip)\n",
    "            predictionLoss  = LA.norm((X@W_s - Y),'fro')\n",
    "            correlation     = np.trace(np.matmul(R,np.matmul(W_s.T,W_s)))\n",
    "            sparsity        = 1.0 - ( count_nonzero(W_s) / float(W_s.size) )  #sum(sum(W_s!=0))\n",
    "            totalloss       = predictionLoss + alpha*correlation + beta*sparsity\n",
    "            if np.absolute(oldloss - totalloss) <= miniLossMargin:\n",
    "                break\n",
    "            elif totalloss <=0:\n",
    "                break\n",
    "            else:\n",
    "                oldloss = totalloss\n",
    "            iteration+=1\n",
    "        return W_s\n",
    "    \n",
    "    threshold = optmParameter['Threshold']\n",
    "    \n",
    "    #This function predicts the output label matrix.\n",
    "    \n",
    "    def LLSF_prediction(Xt,weightmat,threshold):\n",
    "        St    = np.matmul(Xt,weightmat)\n",
    "        Y_pre = np.maximum(np.sign(St - threshold),0)\n",
    "        return Y_pre\n",
    "    \n",
    "    weightmat = LLSF_weight_mat(X,Y,optmParameter)\n",
    "    results   = LLSF_prediction(Xt,weightmat,threshold)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = LLSF(X,Y,Xt,optmParameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss : 0.22194719471947194\n",
      "zero_one_loss : 0.7623762376237624\n",
      "coverage_error : 4.599009900990099\n",
      "label_ranking_average_precision_score : 0.6170242024202425\n"
     ]
    }
   ],
   "source": [
    "print('Hamming loss : {}'.format(hamming_loss(Yt,results)))\n",
    "print('zero_one_loss : {}'.format(zero_one_loss(Yt,results)))\n",
    "print('coverage_error : {}'.format(coverage_error(Yt,results)))\n",
    "print('label_ranking_average_precision_score : {}'.format(label_ranking_average_precision_score(Yt,results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
